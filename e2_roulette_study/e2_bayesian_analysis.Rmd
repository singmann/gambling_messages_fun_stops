
---
title: "Analysis Roulette Gambling Study"
author: "Philip W. S. Newall, Leonardo Weiss-Cohen, Henrik Singmann, Lukasz Walasek, & Elliot A. Ludvig"
date: "Analysis by Henrik Singmann; Script run on `r format(Sys.time(), '%d. %B %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
### run with R 4.0.2
library("checkpoint")
checkpoint("2020-07-01")
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(dpi=200, out.width="70%", fig.asp = 0.618,
                      fig.width=4, fig.align = "center")
options(width = 110)
options("dplyr.summarise.inform" = FALSE)
options(pillar.sigfig = 3)
options(mc.cores = parallel::detectCores()) # fitting uses multicore by default
```

# Preparation

```{r, message=FALSE, warning=FALSE, results='hide'}
library("tidyverse")
#library("tidylog")
theme_set(theme_bw() + 
            theme(panel.grid.major.x = element_blank(), 
                  panel.grid.minor.x = element_blank()))
library("brms")  # requires compilation tools for model fitting
library("tidybayes")
library("BayesFactor")
library("binom")
par_labels <- c("Gamble at all?", 
                "Gamble everything?", 
               "Proportion bet?")
cond_labels <- c("None", "White", "Yellow")
ylabel <- "Gambling message"
```

## Load & Prepare Data

We first load in the data from all participants and transform variables into correct type. We then remove those participants that did not solve enough captchas correctly and only retain some relevant variables. We also prepare remove data from two participants for which for unknown (likely technical) reasons not all data was collected.

```{r, message=FALSE, warning=FALSE}

exclude_ids <- c("P0181", "P1476")

part <- read_csv("data/participants_anon.csv") %>% 
  mutate(exp_cond = factor(exp_cond, levels = 
                             c("none", "white", "yellow")), 
         bonus = as.numeric(bonus), 
         bet_count = as.numeric(bet_count))
part2 <- part %>% 
  filter(!is.na(exp_cond)) %>% 
  select(ppt_id, exp_cond, bonus, bet_count)
```

Next we load in the data from all bets, create the variables of interest and join with the participants data. Then, we do not forget to set all NAs to zero (participants who did not have betting data are those that skipped betting though have a total bet and win amount of 0). Then we create the oyr DV, proportion of money bet, as follows:
$$\texttt{prop_bet} = \frac{\texttt{amount}}{3 + \texttt{total_win}}$$

```{r, message=FALSE, warning=FALSE, include=FALSE}
bets <- read_csv("data/bets_anon.csv")
bets2 <- bets %>% 
  group_by(ppt_id) %>% 
  summarise(amount = sum(abs(total_amt_bet)), 
            total_win = sum(win)) 

part2 <- left_join(part2, bets2) %>% 
  mutate(amount = if_else(is.na(amount), 0, amount),
         total_win = if_else(is.na(total_win), 0, total_win)) %>% 
  mutate(new_prop = amount/ (3 + total_win)) %>% 
  mutate(new_prop = if_else(new_prop > 1, 1, new_prop)) ## necessary: few values are just above 1
part2 <- part2 %>% 
  filter(!(ppt_id %in% exclude_ids))
```

```{r, include=FALSE}
covariates <- read_csv("data/questions_anon.csv") %>% 
  mutate(across(starts_with("PGSI"), ~case_when(
    . == "Never" ~ 0,
    . == "Sometimes" ~ 1,
    . == "MostTime" ~ 2, 
    . == "Always" ~ 3, 
    TRUE ~ NA_real_))) %>% 
  mutate(across(starts_with("Motives"), ~case_when(
    . == "Never" ~ 0,
    . == "Sometimes" ~ 1,
    . == "Often" ~ 2, 
    . == "Always" ~ 3, 
    TRUE ~ NA_real_)))
# map(covariates[,-(1:2)], ~sort(unique(.)))
## PGSI
# 0 = never
# 1 = sometimes
# 2 = most often / often
# 3 = always
pgsi <- covariates %>% 
  #select(-starts_with("Motives")) %>% 
  pivot_longer(starts_with("PGSI")) %>% 
  group_by(ppt_id) %>% 
  summarise(pgsi = sum(value))

motives <- covariates %>% 
  #select(-starts_with("Motives")) %>% 
  pivot_longer(starts_with("Motives")) %>% 
  group_by(ppt_id) %>% 
  summarise(motives = sum(value))

part2 <- left_join(part2, pgsi) %>% 
  left_join(motives) %>% 
  mutate(pgsi_c = pgsi - mean(pgsi),
         motives_c = motives - mean(motives))
```


The analysis is based on the following number of participants 

```{r}
nrow(part2) ## number of participants
part2 %>% 
  group_by(exp_cond) %>% 
  tally()
```


# Payed bonus

Overall bonus paid out was:

```{r}
round(mean(part2$bonus), 2)
```

If we split bonus by whether or not participants played, we see clearly that playing leads to less payout:

```{r}
part2 %>% 
  mutate(bet_at_all = ifelse(bet_count == 0, "no bet", "bet")) %>% 
  group_by(bet_at_all) %>% 
  summarise(mean_bonus = mean(bonus), 
            sd_bonus = sd(bonus), 
            se_bonus = sd(bonus)/sqrt(n()), 
            max_bonus = max(bonus),
            min_bonus = min(bonus))
```


# Distribution of DV

Our DV clearly does not look normally distributed.

```{r}
part2 %>% 
  ggplot(aes(new_prop)) +
  geom_histogram(binwidth = 0.025)
```

```{r}
part2 %>% 
  summarise(gamble_at_all = 1 - mean(new_prop  == 0), 
            gamble_everything = mean(new_prop[new_prop != 0] == 1), 
            proportion_bet_rest = mean(new_prop[!(new_prop %in% c(0, 1))]))


```

Binomial confidence or credibility intervals for the probability to gamble at all:

```{r}
binom.confint(nrow(part2) - sum(part2$new_prop == 0), nrow(part2))
```



# Zero-One Inflated Beta Regression

We use a custom parameterization of a zero-one-inflated beta-regression model (see also [here](https://vuorre.netlify.com/post/2019/02/18/analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/)). The likelihood of the model is given by:

$$\begin{align}
f(y) &= (1 - g) & & \text{if } y = 0 \\
f(y) &= g \times e & & \text{if } y = 1 \\
f(y) &= g \times (1 - e) \times \text{Beta}(a,b) & & \text{if } y \notin \{0, 1\} \\
a &= \mu \times \phi \\
b &= (1-\mu) \times \phi
\end{align}$$

Where $1 - g$ is the zero inflation probability, `zipp` is $g$ and reflects the probability to gamble, $e$ is the conditional one-inflation probability (`coi`) or conditional probability to gamble everything (i.e., conditional probability to have a value of one, if one gambles), $\mu$ is the mean of the beta distribution (`Intercept`), and $\phi$ is the precision of the beta distribution (`phi`). As we use `Stan` for modelling, we need to model on the real line and need appropriate link functions. For `\phi` the link is log (inverse is `exp()`), for all other parameters it is logit (inverse is `plogis()`).

We fit this model and add experimental condition as a factor to the three main model parameters (i.e., only the precision parameter is fixed across conditions). The following table provides the overview of the model and all model parameters and show good convergence.

```{r, eval=TRUE, include=FALSE}
zoib2 <- custom_family(
  "zoib2", dpars = c("mu", "phi", "zipp", "coi"),
  links = c("logit", "log", "logit", "logit"), lb = c(NA, 0, NA, NA),
  type = "real"
)

stan_funs <- "
/* zero-one-inflated beta log-PDF of a single response 
   * Args: 
   *   y: response value 
   *   mu: mean parameter of the beta part
   *   phi: precision parameter of the beta part
   *   zipp: zero-inflation probability parameter
   *   coi: conditional one-inflation probability
   * Returns:  
   *   a scalar to be added to the log posterior 
   */ 
   real zoib2_lpdf(real y, real mu, real phi,
                                    real zipp, real coi) {
     row_vector[2] shape = [mu * phi, (1 - mu) * phi]; 
     if (y == 0) { 
       return bernoulli_lpmf(0 | zipp); 
     } else if (y == 1) {
       return bernoulli_lpmf(1 | zipp) + bernoulli_lpmf(1 | coi);
     } else { 
       return bernoulli_lpmf(1 | zipp) + bernoulli_lpmf(0 | coi) + beta_lpdf(y | shape[1], shape[2]);
     } 
   }
"
stanvars <- stanvar(scode = stan_funs, block = "functions")


zoib_model <- bf(
  new_prop ~ exp_cond,
  phi ~ 1,
  zipp ~ exp_cond,
  coi ~ exp_cond, 
  family = zoib2
)

np <- prior_string("target += logistic_lpdf(Intercept_zipp | 0, 1);", check = FALSE)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y
tmp_model_filename <- "model_fits/model_zoib.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib <- brm(formula = zoib_model, data = part2, 
               stanvars = stanvars, prior = np, 
               iter = 26000, warmup = 1000, chains = 4) ## 100,000 post-warmup
save(mzoib, file = tmp_model_filename, compress = "xz")
}

```


```{r}
summary(mzoib)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib, pars = "_condyellow")
```

Likewise, we can plot the three parameters showing the difference distribution of the white message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib, pars = "_condwhite")
```



```{r, include=FALSE}
get_variables(mzoib)
```


The model does not have any obvious problems, even without priors for the condition specific effects.

## Posterior Predictive Checks

As expected the synthetic data generated from the model looks a lot like the actual data. This suggests that the model is adequate for the data.

```{r}
## we need to create a custom RNG function for this case
posterior_predict_zoib2 <- function(i, prep, ...) {
  zi <- brms:::get_dpar(prep, "zipp", i)
  coi <- brms:::get_dpar(prep, "coi", i)
  mu <- brms:::get_dpar(prep, "mu", i = i)
  phi <- brms:::get_dpar(prep, "phi", i = i)
  hu <- runif(prep$nsamples, 0, 1)
  hu2 <- runif(prep$nsamples, 0, 1)
  #one_or_zero <- runif(prep$nsamples, 0, 1)
  ifelse(hu > zi, 0, 
    ifelse(hu2 < coi, 1, 
           rbeta(prep$nsamples, shape1 = mu * phi, shape2 = (1 - mu) * phi)
  ))
}

```

```{r, fig.width=6, out.width="100%"}
pp1 <- pp_check(mzoib, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350)) +
  theme(legend.position = "none")
pp1
ggsave(plot = pp1, filename = "figures/ppp.png", width = 8, height = 6)

```

## Model Estimates

We first give the table showing the posterior means and 95% CIs.

```{r, warning=FALSE}

lpars <- mzoib %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(.variable != "b_phi_Intercept") %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "condyellow") ~ "yellow",
    str_detect(.variable, "condwhite") ~ "white"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(None = Intercept, 
         White = Intercept + white,
         Yellow = Intercept + yellow) %>% 
  select(-Intercept, -white, -yellow) %>% 
  pivot_longer(cols = c(None, White, Yellow), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

condpars %>% 
  group_by(parameter, condition) %>% 
  mean_qi()

```

For the zero-one inflated components, we can compare the model estimates with the data. Not unsurprisingly, they match quite well. 

```{r}
part2 %>% 
  group_by(exp_cond) %>% 
  summarise(gamble_at_all = 1 - mean(new_prop  == 0), 
            gamble_everything = mean(new_prop[new_prop != 0] == 1))
```

The following is the main results figure on the level of the message conditions.


```{r, out.width="100%", fig.width = 9.5, fig.asp=0.5}
## plots in which CIs sizes are relative to each other.
tmp <- condpars %>% 
  group_by(parameter, condition) %>% 
  mean_qi()
tmp <- tmp %>% 
  mutate(width = .upper - .lower) %>% 
  summarise(mwidth = mean(width))
pr1 <- condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") + ylab(ylabel) +
  scale_x_continuous(labels = scales::percent_format(1))
tmp2 <- pr1$data %>% 
  group_by(parameter) %>% 
  summarise(min = min(estimate), 
            max = max(estimate)) %>% 
  mutate(fwidth = max - min) %>% 
  mutate(newmin = min, 
         newmax = max, 
         mid = min + fwidth * 0.5)
tmp2$fac <- tmp$mwidth/tmp2$fwidth
tmp2$ciwdith <- tmp$mwidth
tmp2 <- tmp2 %>% 
  mutate(newwidth = ciwdith * 1/min(fac)) %>% 
  mutate(newmin = mid - newwidth/2,
         newmax = mid + newwidth/2)
tmpl <- tmp2 %>% 
  select(parameter, newmin, newmax) %>% 
  pivot_longer(cols = c(newmin, newmax), 
               names_to = "bounds", values_to = "estimate") %>% 
  mutate(condition = NA)
pr1 <- pr1 +
  geom_blank(data = tmpl)

pr1 + theme_bw(base_size = 17)
ggsave(pr1  + theme_bw(base_size = 17), filename = "figures/res_e1a.png", 
       width = 9.5, height = 4.5)
ggsave(pr1  + theme_bw(base_size = 17) + theme(panel.grid.minor.x = element_blank()), 
       filename = "figures/res_e1b.png", 
       width = 9.5, height = 4.5)
ggsave(pr1  + theme_bw(base_size = 17) + theme(
  panel.grid.minor.x = element_blank(), 
  panel.grid.major.x = element_blank()), 
       filename = "figures/res_e1c.png", 
       width = 9.5, height = 4.5)
pr1use <- pr1  + theme_bw(base_size = 17) + theme(
  panel.grid.minor.x = element_blank(), 
  panel.grid.major.x = element_blank())
```


```{r, out.width="100%", fig.width = 9.5, fig.asp=0.5, eval=FALSE}
## not used at the moment because of preceding chunk 
pr1 <- condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") + ylab(ylabel) +
  scale_x_continuous(labels = scales::percent_format(1))
pr1 + theme_bw(base_size = 17)
ggsave(pr1  + theme_bw(base_size = 17), filename = "figures/res_e1.png", 
       width = 9.5, height = 4.5)
```

## Difference distribution versus no message condition

We can also focus and look at the difference distributions from the no message condition (i.e., we do not show the "Yellow versus White" comparison, but all below are against no message condition).

```{r}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  filter(condition != "Yellow - White") %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("White - None", "Yellow - None"), 
    labels = c("White", "Yellow")))
comppars %>% 
  group_by(parameter, condition) %>% 
  mean_qi()
```

Same as a figure.


```{r, out.width="100%", fig.width = 9.5, fig.asp=0.4}

pr2 <- comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey", size = 0.6) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Difference from no message condition (on probability/proportion scale)") + 
  ylab("No message vs.") +
  scale_x_continuous(labels = scales::percent_format(1)) 

ciwidths <- comppars %>% 
  group_by(parameter, condition) %>% 
  mean_qi() %>% 
  mutate(width = .upper - .lower) %>% 
  summarise(mwdith = mean(width))

tmp <- pr2$data %>% 
  group_by(parameter) %>% 
  summarise(min = min(estimate), 
            max = max(estimate)) %>% 
  mutate(pwidth = max-min) %>% 
  mutate(mid = min + (max-min)/2) %>% 
  mutate(ciwdith = ciwidths$mwdith) %>% 
  mutate(newwidth = ciwdith * max(pwidth/ciwdith)) %>% 
  mutate(newmin = mid - newwidth/2,
         newmax = mid + newwidth/2)
tmpl <- tmp %>% 
  select(parameter, newmin, newmax) %>% 
  pivot_longer(cols = c(newmin, newmax), 
               names_to = "bounds", values_to = "estimate") %>% 
  mutate(condition = NA)
pr2 <- pr2 +
  geom_blank(data = tmpl)

pr2 + theme_bw(base_size = 17) + 
  theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank()
  )

ggsave(pr2  + theme_bw(base_size = 17) + theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank()
  ), filename = "figures/res_e2.png", 
       width = 9.5, height = 4)
pr2use <- pr2  + theme_bw(base_size = 17) + theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank()
  )
```

```{r}
ggsave(plot = cowplot::plot_grid(pr1use, pr2use, ncol = 1, 
                                 rel_heights = c(4.5, 4)), 
       filename = "figures/res_both.png", 
       width = 9.5, height = 8.5)

```


## All Difference Distributions

For reference, we below include another plot of the difference distributions but this time include the distribution comparing the Yellow versus White warning message comparison as well.

```{r}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("Yellow - White", "White - None", "Yellow - None")))
comppars %>% 
  group_by(parameter, condition) %>% 
  mean_qi()
```


```{r, out.width="100%", fig.width=6, fig.asp=0.5}

comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("No message vs.") +
  scale_x_continuous(labels = scales::percent_format(1))

# ggsave(pr1  + theme_bw(base_size = 17), filename = "res_e1.png", 
#        width = 9.5, height = 4.5)
```

## All Difference Distributions with Possible Priors

The following plot shows the estimated differences from the no message control condition with overlayed density estimate (in black) and some possible prior distributions in colour (note again that the model did not actually include any priors). These differences are shown on the linear scale before applying the logistic link function. These priors are normal priors (who have a higher peak at 0 compared to Cauchy and t) with different SDs.

```{r}
prior_pars <- lpars %>% 
  filter(type != "Intercept") %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels)) %>% 
  mutate(
    type = paste0("No message vs. ", type)
  )
# prior_pars %>% 
#   unique(.$.variable)
```

```{r, out.width="100%", fig.width=8, warning=FALSE}
prior_plot <- prior_pars %>% 
  ggplot() +
  geom_histogram(aes(.value, after_stat(density)), binwidth = 0.001) +
  geom_density(aes(.value)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = c(0.25)), 
                mapping =  aes(color = "SD = 0.25")) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = c(0.5)), 
                mapping =  aes(color = "SD = 0.5")) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = c(1)), 
                mapping =  aes(color = "SD = 1.00")) +
  geom_vline(xintercept = 0, color = "grey") +
  facet_grid(rows = vars(type), 
             cols = vars(parameter), scales = "free_x") + 
  guides(colour = guide_legend("prior width")) +
  labs(x = "estimate on linear scale") +
  ggsci::scale_color_lancet()
prior_plot
```

```{r, eval=FALSE}
if (dir.exists("../figures/")) {
  ggsave("../figures/e2_prior_plot.png", device = "png", 
         width = 19, height = 9, units = "cm", 
         dpi = 600)
  ggsave("../figures/e2_prior_plot.pdf", device = "pdf", 
         width = 19, height = 9, units = "cm", 
         dpi = 600)
}
```


```{r, eval=FALSE}

plogis(qnorm(0.975) * 1) - 0.5

```


In this figure we considered three prior width. For a prior width of SD = 0.25 we expect with 95% that the largest possible effect we observe is `r scales::percent(plogis(qnorm(0.975) * 0.25) - 0.5, accuracy = 0.01)` on the response scale. For a prior width of SD = 0.5 we expect with 95% that the largest possible effect we observe is `r scales::percent(plogis(qnorm(0.975) * 0.5) - 0.5, accuracy = 0.01)` on the response scale. For a prior width of SD = 0.5 we expect with 95% that the largest possible effect we observe is `r scales::percent(plogis(qnorm(0.975) * 1) - 0.5, accuracy = 0.01)` on the response scale.

What the figure shows is that for "gamble at all" the evidence is mostly anecdotal for the null hypothesis of no difference. That is, the posterior density at 0 (i.e., y-axis position at which the black line crosses the 0 line) is somewhat larger than the prior density at 0 (i.e., the density of the prior curve at 0). However the ratio of the two densities does not appear to exceed 3. For the most narrow prior (SD = 0.25) the two densities are approximately equal implying no evidence either way (i.e., neither for null nor for a difference). 

For "gamble everything" all priors suggest evidence for the null hypothesis, although this evidence only appears to exceed the anecdotal threshold of a ratio of 3 for the wide prior (SD = 1). 

For "proportion bet", we see a similar picture for the comparison with the white message (i.e., anecdotal evidence for the null). For the comparison with the yellow message the data appears to provide evidence for the backfire effect. The other two priors again provide only anecdotal evidence for the null.
   

## Control versus Warning Label

We now look at the data but aggregate both gambling message conditions into one (i.e., we only have no message versus message).

```{r}
condpars2 <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         warning = Intercept + (white + yellow)/2) %>% 
  select(-Intercept, -white, -yellow) %>% 
  pivot_longer(cols = c(control, warning), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

condpars2 %>% 
  group_by(parameter, condition) %>% 
  mean_qi()
```



```{r, out.width="100%", fig.width=6, fig.asp=0.4}
condpars2 %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(accuracy = 0.1))
```

```{r}
comppars2 <- condpars2 %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) 
comppars %>% 
  group_by(parameter, condition) %>% 
  mean_qi()
```


```{r, out.width="100%", fig.width=6, fig.asp=0.3}

comppars2 %>% 
  ggplot(aes(x = estimate, y = 1)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("No message vs. gambling message") +
  scale_x_continuous(labels = scales::percent_format())
```



# Model With Covariates

## Plot of Relationships and BANOVA
The covariates do not differ between conditions (strong BF evidence for the null).

```{r, warning=FALSE}
1/anovaBF(pgsi ~ exp_cond, part2, progress = FALSE)
1/anovaBF(motives ~ exp_cond, part2, progress = FALSE)
```


The following table shows mean and SDs of the covariates per group.

```{r}
part2 %>% 
  group_by(exp_cond) %>% 
  summarise(across(c(pgsi, motives), list(mean = mean, sd = sd)))
```


The following plot shows the relationships of the covariates among each other and with proportion bet.

```{r, message=FALSE, out.width="100%", fig.width=12, fig.height=4, fig.asp=0.4}
tmpp1 <- part2 %>% 
  #filter(!(new_prop %in% c(1))) %>% 
  ggplot(aes(x = pgsi, y = motives)) +
  geom_jitter(alpha = 0.2, width = 0.01, height = 0.2) +
  geom_smooth() +
  geom_smooth(method = "lm", color = "red")
tmpp2 <- part2 %>% 
  #filter(!(new_prop %in% c(1))) %>% 
  ggplot(aes(x = new_prop, y = motives)) +
  geom_jitter(alpha = 0.2, width = 0.01, height = 0.2) +
  geom_smooth() +
  geom_smooth(method = "lm", color = "red")
tmpp3 <- part2 %>% 
  #filter(!(new_prop %in% c(1))) %>% 
  ggplot(aes(x = new_prop, y = pgsi)) +
  geom_jitter(alpha = 0.2, width = 0.01, height = 0.2) +
  geom_smooth() +
  geom_smooth(method = "lm", color = "red")
cowplot::plot_grid(tmpp1, tmpp2, tmpp3, nrow = 1)
```

The figures show some relationships which can also be seen when just looking at the correlation.

```{r}
cor.test(part2$pgsi, part2$motives)
cor.test(part2$pgsi, part2$new_prop)
cor.test(part2$motives, part2$new_prop)
```

The figure below provides an alternative visualisation of the relationships between covariates and betting behaviour. In particular, participants were categorized into one of three experimental betting behavior groups: participants who did not bet at all (“none”, 14% of participants), participants who bet some of their money (68% of participants), and participants who bet “all” of their money (18%). For both gambling scales we see a positive relationship between the betting behavior group and the gambling score. Participants who bet more have on average higher scores on the two gambling scales. 


```{r}

part2 <- part2 %>% 
  mutate(gamble_cat = if_else(new_prop == 1, "all", if_else(new_prop == 0, "none", "some"))) %>% 
  mutate(gamble_cat = factor(gamble_cat, levels = c("none", "some", "all")))
#library("ggbeeswarm")

prop.table(table(part2$gamble_cat))

cvp1 <- part2 %>% 
  #filter(!(new_prop %in% c(0))) %>% 
  #ggplot(aes(x = interaction(exp_cond, gamble_cat), y = pgsi)) +
  ggplot(aes(x = gamble_cat, y = pgsi)) +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
  #geom_quasirandom(alpha = 0.2) +
  stat_summary(fun.data = ~mean_se(., mult = 1.96)) +
  xlab("Proportion bet") + ylab("Enhancement Motives") +
  theme_bw(base_size = 15) + theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank()
  )

cvp2 <- part2 %>% 
  #filter(!(new_prop %in% c(0))) %>% 
  #ggplot(aes(x = interaction(exp_cond, gamble_cat), y = pgsi)) +
  ggplot(aes(x = gamble_cat, y = motives)) +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
  #geom_quasirandom(alpha = 0.2) +
  stat_summary(fun.data = ~mean_se(., mult = 1.96)) +
  xlab("Proportion bet") + ylab("Problem Gambling Severity Index") + 
  theme_bw(base_size = 15) + theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank()
  )
cvp <- cowplot::plot_grid(cvp2, cvp1)
ggsave(filename = "figures/cov_plot.png", plot = cvp, width = 6.5, height = 4)

cvp

```

This is supported by Bayesian ANOVAs with Bayes factors of over 400,000 for the effect of betting behavior group on the gambing scale scores. However, this effect was not moderated by gambling message condition. In particular, there was evidence for the absence of both a main effect of gambling message condition and an interaction of gambling message condition with betting behaviour group for both gambling scale scores (Bayes factors for the null > 25).

```{r, eval=FALSE}
anovaBF(pgsi ~ gamble_cat, part2, progress = FALSE)
anovaBF(motives ~ gamble_cat, part2, progress = FALSE)
```

```{r, warning=FALSE}
bfa1 <- anovaBF(pgsi ~ gamble_cat*exp_cond, part2, progress = FALSE)
bfa1
bfa1[2]/bfa1

bfa2 <- anovaBF(motives ~ gamble_cat*exp_cond, part2, progress = FALSE)
bfa2
bfa2[2]/bfa2
```



## Model with Both Main Effects

```{r, eval=TRUE, include=FALSE}
zoib_model2 <- bf(
  new_prop ~ exp_cond + pgsi_c + motives_c,
  phi ~ 1,
  zipp ~ exp_cond + pgsi_c + motives_c,
  coi ~ exp_cond + pgsi_c + motives_c, 
  family = zoib2
)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib2.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib2 <- brm(formula = zoib_model2, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib2, file = tmp_model_filename, compress = "xz")
}



```

```{r}
summary(mzoib2)
```

As a visual convergence check, we plot the density and trace plots for the four intercept pasrameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib2, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib2, pars = "_condyellow")
```

Likewise, we can plot the three parameters showing the difference distribution of the white message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib2, pars = "_condwhite")
```


```{r, include=FALSE}
get_variables(mzoib2)
```

```{r, fig.width=6, out.width="100%"}
pp_check(mzoib2, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350))
```



```{r}

lpars <- mzoib2 %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(!(.variable %in% c("b_phi_Intercept"))) %>%
  filter(!str_detect(.variable, "pgsi|motives")) %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "condyellow") ~ "yellow",
    str_detect(.variable, "condwhite") ~ "white"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))
#unique(lpars$.variable)

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         white = Intercept + white,
         yellow = Intercept + yellow) %>% 
  select(-Intercept) %>% 
  pivot_longer(cols = c(control, white, yellow), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

```

```{r, out.width="100%", fig.width=6, fig.asp=0.55}
condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(1))
```


```{r, out.width="100%", fig.width=6, fig.asp=0.55}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("yellow - white", "white - control", "yellow - control")))
comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
    xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("No message vs.") +
  scale_x_continuous(labels = scales::percent_format(1))
```

## Model with PGSI Main Effect

```{r, eval=TRUE, include=FALSE}
zoib_model2p <- bf(
  new_prop ~ exp_cond + pgsi_c,
  phi ~ 1,
  zipp ~ exp_cond + pgsi_c,
  coi ~ exp_cond + pgsi_c, 
  family = zoib2
)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib2p.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib2p <- brm(formula = zoib_model2p, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib2p, file = tmp_model_filename, compress = "xz")
}

```

```{r}
summary(mzoib2p)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib2p, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib2p, pars = "_condyellow")
```

Likewise, we can plot the three parameters showing the difference distribution of the white message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib2p, pars = "_condwhite")
```


```{r, include=FALSE}
get_variables(mzoib2)
```

```{r, fig.width=6, out.width="100%"}
pp_check(mzoib2p, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350))
```



```{r}

lpars <- mzoib2p %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(!(.variable %in% c("b_phi_Intercept"))) %>%
  filter(!str_detect(.variable, "pgsi|motives")) %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "condyellow") ~ "yellow",
    str_detect(.variable, "condwhite") ~ "white"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))
#unique(lpars$.variable)

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         white = Intercept + white,
         yellow = Intercept + yellow) %>% 
  select(-Intercept) %>% 
  pivot_longer(cols = c(control, white, yellow), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

```

```{r, out.width="100%", fig.width=6, fig.asp=0.55}
condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(1))
```


```{r, out.width="100%", fig.width=6, fig.asp=0.55}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("yellow - white", "white - control", "yellow - control")))
comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
    xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("No message vs.") +
  scale_x_continuous(labels = scales::percent_format(1))
```

## Model with Motives Main Effects

```{r, eval=TRUE, include=FALSE}
zoib_model2 <- bf(
  new_prop ~ exp_cond + motives_c,
  phi ~ 1,
  zipp ~ exp_cond + motives_c,
  coi ~ exp_cond + motives_c, 
  family = zoib2
)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib2m.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib2m <- brm(formula = zoib_model2, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib2m, file = tmp_model_filename, compress = "xz")
}



```

```{r}
summary(mzoib2m)
```

As a visual convergence check, we plot the density and trace plots for the four intercept pasrameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib2m, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib2m, pars = "_condyellow")
```

Likewise, we can plot the three parameters showing the difference distribution of the white message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib2m, pars = "_condwhite")
```


```{r, include=FALSE}
get_variables(mzoib2m)
```

```{r, fig.width=6, out.width="100%"}
pp_check(mzoib2m, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350))
```

```{r}

lpars <- mzoib2m %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(!(.variable %in% c("b_phi_Intercept"))) %>%
  filter(!str_detect(.variable, "pgsi|motives")) %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "condyellow") ~ "yellow",
    str_detect(.variable, "condwhite") ~ "white"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))
#unique(lpars$.variable)

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         white = Intercept + white,
         yellow = Intercept + yellow) %>% 
  select(-Intercept) %>% 
  pivot_longer(cols = c(control, white, yellow), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

```

```{r, out.width="100%", fig.width=6, fig.asp=0.55}
condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(1))
```


```{r, out.width="100%", fig.width=6, fig.asp=0.55}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("yellow - white", "white - control", "yellow - control")))
comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
    xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("No message vs.") +
  scale_x_continuous(labels = scales::percent_format(1))
```


## Model With Interactions (Both Variables)

```{r, eval=TRUE, include=FALSE}
zoib_model3 <- bf(
  new_prop ~ exp_cond * (pgsi_c + motives_c),
  phi ~ 1,
  zipp ~ exp_cond * (pgsi_c + motives_c),
  coi ~ exp_cond * (pgsi_c + motives_c), 
  family = zoib2
)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib3.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib3 <- brm(formula = zoib_model3, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib3, file = tmp_model_filename, compress = "xz")
}
```


```{r}
summary(mzoib3)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib3, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib3, pars = "_condyellow$")
```

Likewise, we can plot the three parameters showing the difference distribution of the white message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib3, pars = "_condwhite$")
```



```{r, include=FALSE}
get_variables(mzoib2)
```

```{r, fig.width=6, fig.height=6, out.width="100%"}
pp_check(mzoib3, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350))
```



```{r}

lpars <- mzoib3 %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(!(.variable %in% c("b_phi_Intercept"))) %>%
  filter(!str_detect(.variable, "pgsi|motives")) %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "condyellow") ~ "yellow",
    str_detect(.variable, "condwhite") ~ "white"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))
#unique(lpars$.variable)

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         white = Intercept + white,
         yellow = Intercept + yellow) %>% 
  select(-Intercept) %>% 
  pivot_longer(cols = c(control, white, yellow), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

```

```{r, out.width="100%", fig.width=6}
condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(1))
```


```{r, out.width="100%", fig.width=6}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("yellow - white", "white - control", "yellow - control")))
comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("No message vs.") +
  scale_x_continuous(labels = scales::percent_format(1))
```

## Model With Interactions (Only PGSI)

```{r, eval=TRUE, include=FALSE}
zoib_model3p <- bf(
  new_prop ~ exp_cond * pgsi_c,
  phi ~ 1,
  zipp ~ exp_cond * pgsi_c,
  coi ~ exp_cond * pgsi_c, 
  family = zoib2
)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib3p.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib3p <- brm(formula = zoib_model3p, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib3p, file = tmp_model_filename, compress = "xz")
}
```


```{r}
summary(mzoib3p)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib3p, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib3p, pars = "_condyellow$")
```

Likewise, we can plot the three parameters showing the difference distribution of the white message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib3p, pars = "_condwhite$")
```



```{r, include=FALSE}
get_variables(mzoib2)
```

```{r, fig.width=6, fig.height=6, out.width="100%"}
pp_check(mzoib3p, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350))
```



```{r}

lpars <- mzoib3p %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(!(.variable %in% c("b_phi_Intercept"))) %>%
  filter(!str_detect(.variable, "pgsi|motives")) %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "condyellow") ~ "yellow",
    str_detect(.variable, "condwhite") ~ "white"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))
#unique(lpars$.variable)

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         white = Intercept + white,
         yellow = Intercept + yellow) %>% 
  select(-Intercept) %>% 
  pivot_longer(cols = c(control, white, yellow), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

```

```{r, out.width="100%", fig.width=6}
condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(1))
```


```{r, out.width="100%", fig.width=6}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("yellow - white", "white - control", "yellow - control")))
comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("No message vs.") +
  scale_x_continuous(labels = scales::percent_format(1))
```

## Model With Interactions (Only Motives)

```{r, eval=TRUE, include=FALSE}
zoib_model3m <- bf(
  new_prop ~ exp_cond * motives_c,
  phi ~ 1,
  zipp ~ exp_cond * motives_c,
  coi ~ exp_cond * motives_c, 
  family = zoib2
)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib3m.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib3m <- brm(formula = zoib_model3m, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib3m, file = tmp_model_filename, compress = "xz")
}
```


```{r}
summary(mzoib3m)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib3m, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib3m, pars = "_condyellow$")
```

Likewise, we can plot the three parameters showing the difference distribution of the white message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib3m, pars = "_condwhite$")
```



```{r, include=FALSE}
get_variables(mzoib2)
```

```{r, fig.width=6, fig.height=6, out.width="100%"}
pp_check(mzoib3m, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350))
```



```{r}

lpars <- mzoib3m %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(!(.variable %in% c("b_phi_Intercept"))) %>%
  filter(!str_detect(.variable, "pgsi|motives")) %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "condyellow") ~ "yellow",
    str_detect(.variable, "condwhite") ~ "white"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))
#unique(lpars$.variable)

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         white = Intercept + white,
         yellow = Intercept + yellow) %>% 
  select(-Intercept) %>% 
  pivot_longer(cols = c(control, white, yellow), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

```

```{r, out.width="100%", fig.width=6}
condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(1))
```


```{r, out.width="100%", fig.width=6}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("yellow - white", "white - control", "yellow - control")))
comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("No message vs.") +
  scale_x_continuous(labels = scales::percent_format(1))
```


# Riskiness of Bets

Do either of the warning labels affect the riskiness of bets chosen in the roulette? Different bets come with different potential payoffs in roulette. If £1 is bet, then this can provide a total payoff of between £2 (e.g., bets on red or black) and £36 (bets on a single number). These numbers, 2 and 36, are the decimal odds for these two bets, representing the total potential payoff Additionally, gamblers can place multiple bets per spin, (e.g., betting £0.50 on red and £0.50 on 7). Since the number 7 is a red colour, the bet on 7 can only win if the first bet on red also wins. Multiple bets per spin can either be placed in a way that accentuates risk, as in this example, or in a way that hedges risk (for example, a bet on black added to the bet on 7, or betting on reds and blacks together). The purpose of this exploratory analysis is to see if either warning label affects risk taking.
 
Following our pre-registration we have measures the amount of risk taken by looking at the variance of the decimal odds for each number in the roulette table. It will measure the concentration of the bet, with more risk represented by more concentrated bets (e.g., betting on a single number), and lower risk represented by more spread bets (e.g., betting on reds, betting on evens). For example, if a participant places a bet on number 7, the decimal odds for that number is 36 (36 times the amount bet if the roulette stops on the number 7). If a participant places a bet on red, then every red number on the table gets a decimal odd of 2 (the participant will win twice the amount bet if the roulette stops on any red number). In order to calculate the proposed risk variable, we will also assign decimal odds of zero for the numbers in which participants did not bet (since they win zero times the amount bet if the roulette stops on those numbers). In the two examples above, every number except 7 will be assigned zero, and every non-red number will be assigned zero, respectively. The risk variable will be the variance of the array of decimal odds for every number on the roulette table, taking into account the bets the participant has placed, and including zeroes for non-winning numbers. The value of this risk variable can range between 0.03 and 35.03. The value cannot be zero in our task because participants are not able to bet the same amount across all numbers including the zero due to the limitations in the values of the available tokens and total bet amounts. Higher numbers indicate more risk taking (with the highest, 35.03, associated with concentrating the bet on a single number). Lower numbers indicate lower risk taking (with the lowest, 0.03, associated with spreading the bet across every red and black number, excluding zero).

The following plot shows the distribution of this variable after aggregating within participants. The left plot shows the original variable on the scale from 0.03 to 35.03. The middle plot shows the variable after dividing by 36 so that the variable ranges from just above 0 to just below 1. The right plot shows the variable after subtracting 0.03 and dividing by 35 so that the smallest value is mapped to 0 and the largest value is mapped to 1. 


```{r, out.width="100%", fig.width=6, fig.asp=0.5}
bets2 <- left_join(bets, select(part2, ppt_id, exp_cond), by = "ppt_id") %>% 
  filter(!(ppt_id %in% exclude_ids)) %>% 
  mutate(average_odds2 = average_odds / 36) %>% 
  mutate(average_odds3 = (average_odds - 0.03) / 35)

bets_av <- bets2 %>% 
  group_by(exp_cond, ppt_id) %>% 
  summarise(across(starts_with("average_odds"), mean)) %>% 
  ungroup()

# bets2 %>% 
#   summarise(mean(average_odds3 == 0),
#             mean(average_odds3 == 1))
# 
# bets_av %>% 
#   summarise(mean(average_odds3 == 0),
#             mean(average_odds3 == 1))

cowplot::plot_grid(
  bets_av %>% 
  ggplot(aes(average_odds)) +
  geom_histogram(bins = 50), 
  bets_av %>% 
  ggplot(aes(average_odds2)) +
  geom_histogram(bins = 50), 
  bets_av %>% 
  ggplot(aes(average_odds3)) +
  geom_histogram(bins = 50), nrow = 1
)

  #facet_wrap("exp_cond")
```

## Beta Regression

We first analyse the data with a beta-regression model. For this, the data needs to be between 0 and 1, but exclude exactly 0 and 1. Consequently, we use the transformation shown above in the middle panel. As before, we fit the data and allow for an effect of gambling message. 


```{r, eval=TRUE, include=FALSE}
risk_frml2 <- bf(
  average_odds2 ~ exp_cond,
  phi ~ 1
)

# risk_frml <- bf(
#   average_odds3 ~ exp_cond + (1 |s| ppt_id),
#   phi ~ 1,
#   zoi ~ exp_cond + (1 |s| ppt_id),
#   coi ~ exp_cond + (1 |s| ppt_id)
# )

# zoib_model <- bf(
#   new_prop ~ exp_cond,
#   phi ~ 1,
#   zipp ~ exp_cond,
#   coi ~ exp_cond, 
#   family = zoib2
# )

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y
tmp_model_filename <- "model_fits/model_risk2.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mrisk2 <- brm(formula = risk_frml2, data = bets_av, family = Beta())
  save(mrisk2, file = tmp_model_filename, compress = "xz")
}

```

The model does not show any obvious problems. In addition, we can see that the 95%-CIs for the gambling message specific effects both include 0.

```{r}
summary(mrisk2)
```

```{r, fig.asp=1.0}
plot(mrisk2)
```

The posterior predictive distribution shows some problems, but at least the shape of the synthetic data is similar to the distribution of the actual data (posterior predictive distributions of a model assuming a Gaussian response distribution was considerably worse and is therefore not incldued here).

```{r, fig.width=6, out.width="100%"}
pp_check(mrisk2, type = "hist", binwidth = 0.05, nsamples = 11)
```

The following tables show the average riskiness per warning label and differences from the no warning message group on the fitted scale, i.e., the (0, 1) scale used for the beta regression.

```{r, warning=FALSE}

lpars <- mrisk2 %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(.variable != "b_phi_Intercept") %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "condyellow") ~ "yellow",
    str_detect(.variable, "condwhite") ~ "white"
  )) 

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw), 
              names_from = type, values_from = .value) %>% 
  mutate(None = Intercept, 
         White = Intercept + white,
         Yellow = Intercept + yellow) %>% 
  select(-Intercept, -white, -yellow) %>% 
  pivot_longer(cols = c(None, White, Yellow), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate))


condpars %>% 
  group_by(condition) %>% 
  mean_qi()
comppars <- condpars %>% 
  #mutate(estimate = estimate * 36) %>% 
  compare_levels(estimate, by = condition) %>% 
  filter(condition != "Yellow - White") %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("White - None", "Yellow - None"), 
    labels = c("White", "Yellow")))

comppars %>% 
  group_by(condition) %>% 
  mean_qi()

```

The following plot shows the distribution of the posteriors (left) and difference from the no message gorup (right). Both of these variables are back-transformed on the original scale from 0.03 to 35.03.

```{r, out.width="100%", fig.width=6, fig.asp=0.55}

p1 <- condpars %>% 
  ggplot(aes(x = estimate * 36, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  xlab("Average Riskiness")

comppars <- condpars %>% 
  mutate(estimate = estimate * 36) %>% 
  compare_levels(estimate, by = condition) %>% 
  filter(condition != "Yellow - White") %>% 
  mutate(condition = factor(
    x = condition, 
    levels = c("White - None", "Yellow - None"), 
    labels = c("White", "Yellow")))
p2 <- comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  geom_halfeyeh() +
    xlab("Difference from no message condition") + 
  ylab("No message vs.")
cowplot::plot_grid(p1, p2, nrow = 1)

```

As is clear from the plots, there is no evidence for a difference. Furthermore, there is some evidence for no difference for the white message, but only ambigous evidence for the yellow message.


## Zero-One Inflated Beta-Regression Model

We also attempt to fit a zero-one inflated beta regression model to the data transformed onto the [0, 1] scale (i.e., right panel in the histograms above). Note that this model uses the `brms` default parameterisation for ZOIBR models and not the custom ones used above.


```{r, eval=TRUE, include=FALSE}
risk_frml <- bf(
  average_odds3 ~ exp_cond,
  phi ~ 1,
  zoi ~ exp_cond,
  coi ~ exp_cond
)

# risk_frml <- bf(
#   average_odds3 ~ exp_cond + (1 |s| ppt_id),
#   phi ~ 1,
#   zoi ~ exp_cond + (1 |s| ppt_id),
#   coi ~ exp_cond + (1 |s| ppt_id)
# )

# zoib_model <- bf(
#   new_prop ~ exp_cond,
#   phi ~ 1,
#   zipp ~ exp_cond,
#   coi ~ exp_cond, 
#   family = zoib2
# )

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_risk.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mrisk <- brm(formula = risk_frml, data = bets_av, 
               family = zero_one_inflated_beta())
  save(mrisk, file = tmp_model_filename, compress = "xz")
}


```

This model also does not show any effect of message condition as none of the effects involving message condition (i.e., variable names containing `exp`) excludes 0 from theit 95% CI.

```{r}
summary(mrisk)
```

Furthermore, the posterior predictive distribution is not actually better. Hence, we prefer the beta regression model above.

```{r, fig.width=6, out.width="100%"}
pp_check(mrisk, type = "hist", binwidth = 0.05, nsamples = 11)
```

# Session Info

```{r}
options(width = 100)
sessionInfo()
```

