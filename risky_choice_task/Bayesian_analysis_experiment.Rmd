---
title: "Bayesian Analysis of Gambling Warning: Risky Choice Experiment"
author: "Philip Newall, Lukasz Walasek, Henrik Singmann, Elliot Ludvig"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width = 100)
```

# Setup

```{r packages, message=FALSE, warning=FALSE, results='hide'}
library("stanova")  ## remotes::install_github("bayesstuff/stanova")
library("brms")
library("emmeans")
library("tidyverse")
library("tidybayes")
theme_set(theme_bw(base_size = 15) + 
            theme(legend.position="bottom"))
source("analysis_fun.R")
library("binom")
options(mc.cores = parallel::detectCores()) # fitting uses multicore by default
```

```{r load}
din <- read_csv("data/Soccerwarnings1.csv", 
                col_types = cols(
                  .default = col_double(),
                  gendertext = col_logical(),
                  comments = col_character(),
                  PROLIFIC_PID = col_character(),
                  ordercontrol = col_character(),
                  orderwarning = col_character()
                )) %>% 
  mutate(newid = factor(1:nrow(.)))

dl <- din %>% 
  select(newid, starts_with("control"), starts_with("warning")) %>% 
  gather("condition", "response", -newid) %>% 
  filter(!is.na(response)) %>% 
  mutate(item = as.numeric(str_extract(condition, "\\d"))) %>% 
  mutate(label = factor(str_remove(condition, "\\d"), 
                            levels = c("warning", "control"))) %>% 
  mutate(complexity = factor(case_when(
    item <= 3 ~ "low",
    item <= 6 ~ "medium",
    item <= 9 ~ "high",
    TRUE ~ NA_character_
  ), levels = c("low", "medium", "high")))
dl %>% 
  group_by(newid) %>% 
  summarise(check = mean(label == "control")) %>% 
  {all(.$check %in% c(0, 1))} ## all newid in one condition only?
```

Two (anonymized) IDs seem to have taken part in the experiment twice.

```{r}
ids <- table(din$PROLIFIC_PID)
ids[ ids > 1 ]
```

We therefore exclude those participants from the data.

```{r}

ids_remove <- din %>% 
  filter(PROLIFIC_PID %in% names(ids[ ids > 1 ])) %>% 
  .$newid

dl <- dl %>% 
  filter(!(newid %in% ids_remove))
```

# Demographics

```{r}
add_vars <- din %>% 
  filter(!(newid %in% ids_remove)) %>% 
  mutate(psg = rowSums(select(., starts_with("pgsi")))) %>% 
  select(newid, gender, age, freq, psg) %>% 
  mutate(gender = factor(gender, levels = 1:4, 
                         labels = c("Male", "Female", "other", "no-answer")), 
         age_z = get_z(age),
         freq_z = get_z(freq),
         psg_z = get_z(psg))
```

Gender distribution:

```{r, warning=FALSE}
any(!is.na(din$gendertext))
add_vars %>% 
  group_by(gender) %>% 
  tally() %>% 
  mutate(p = n / sum(n))
```

Distribution of other covariates:

```{r, fig.width=6, fig.height=3}
add_vars %>% 
  gather("variable", "value", psg, freq, age) %>% 
  ggplot(aes(value)) +
  geom_histogram(bins = 30) +
  facet_wrap("variable", scales = "free")

```

```{r}
add_vars %>% 
  select(psg, freq, age) %>% 
  psych::describe()
```

We can also inspect the inter-correlation among those:

```{r, fig.height=7, fig.width=7, message=FALSE}
add_vars %>% 
  select(age, freq, psg, gender) %>% 
  na.omit() %>% 
  GGally::ggpairs(progress = FALSE, diag = list(continuous = "barDiag"))
```


# Descriptives


```{r}
dl %>% 
  group_by(label) %>% 
  summarise(c = list(binom.confint(sum(response), n = n()))) %>% 
  unnest(c) %>% 
  filter(method == "agresti-coull")
```

The descriptives show a slightly larger rate of choosing the gamble in the warning compared to the control condition.

```{r}
dl %>% 
  group_by(complexity) %>% 
  summarise(c = list(binom.confint(sum(response), n = n()))) %>% 
  unnest(c) %>% 
  filter(method == "agresti-coull")
```

The influence of complexity does not appear to be overly strong or monotonic.

# Bayesian Mixed Models

We first need to aggregate the data to sample efficiently.

```{r}
dla <- dl %>% 
  group_by(complexity, label, newid) %>% 
  summarise(acc = mean(response), 
            nsucc = sum(response == 1),
            nt = n()) %>% 
  ungroup
```


## Models

### Full Fixed Effects

We begin with the maximal-model justified by the design which has by-participant random slopes and by-participant random slopes for complexity as well as correlation among the random-effect parameters.

```{r, eval=TRUE, include=FALSE}

# tmp_model_filename <- "model_fits/model_full.rda"
# if (file.exists(tmp_model_filename)) {
#   load(tmp_model_filename)
# } else {
#   mfull <- stanova_brm(nsucc | trials(nt) ~ label*complexity + (complexity|newid), 
#                        data = dla, family = binomial, 
#                        iter = 11000, warmup = 1000, chains = 4)
#   save(mfull, file = tmp_model_filename, compress = "xz")
# }
mfull <- stanova_brm(nsucc | trials(nt) ~ label*complexity + (complexity|newid),
                     data = dla, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)

```

The model shows no obvious problems.

```{r}
summary(mfull, diff_intercept = TRUE)
```

Furthermore, note that in the case of the term with only two levels (i.e., the `label` main effect), the difference from the intercept is a test of the difference between the two groups. Thus, the 95% CI includes 0 so there is no strong evidence for an effect of the warning label.

```{r}
samp_full <- stanova_samples(mfull, diff_intercept = FALSE, 
                             return = "tidybayes")
```


The following shows the posterior of the mean acceptance probabilities for the two warning label conditions. The data shows a small backfire effect. The participants with label gamble a bit more.

```{r}
samp_full$label %>% 
  mutate(prob = plogis(value)) %>% 
  ggplot(aes(y = variable, x = prob)) +
  stat_halfeye()
  
```

The difference distribution contains 0 for the 95% intervals, but not for the smaller (i.e., 80% or 50%) intervals suggesting some evidence for a backfire effect.

```{r}
ss <- samp_full$label %>% 
  mutate(prob = plogis(value))
levels(ss$variable) <- str_remove(levels(ss$variable), "label ")
ss_diff <- ss %>% 
  pivot_wider(id_cols = -value, names_from = variable, values_from = prob) %>% 
  mutate(diff = warning - control)
ss_diff %>% 
  mean_qi(diff, .width = c(0.5, 0.8, 0.95))

ggplot(ss_diff, aes(diff)) +
  geom_histogram(bins = 100) +
  stat_interval()
  
  
```

We can also look at the results for the minimal model.

```{r, eval=TRUE, include=FALSE}

mri <- stanova_brm(nsucc | trials(nt) ~ label*complexity + (1|newid),
                     data = dla, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)

```

Again, no obvious problems.

```{r}
summary(mri)
```

The results pattern looks like for the maximal model

```{r}
samp_ri <- stanova_samples(mri, diff_intercept = FALSE, 
                             return = "tidybayes")
```



```{r}
samp_ri$label %>% 
  mutate(prob = plogis(value)) %>% 
  ggplot(aes(y = variable, x = prob)) +
  stat_halfeye()
  
```

The difference distribution contains 0 for the 95% intervals, but not for the smaller (i.e., 80% or 50%) intervals suggesting some evidence for a backfire effect.

```{r}
ss2 <- samp_ri$label %>% 
  mutate(prob = plogis(value))
levels(ss2$variable) <- str_remove(levels(ss2$variable), "label ")
ss2_diff <- ss2 %>% 
  pivot_wider(id_cols = -value, names_from = variable, values_from = prob) %>% 
  mutate(diff = warning - control)
ss2_diff %>% 
  mean_qi(diff, .width = c(0.5, 0.8, 0.95))

ggplot(ss2_diff, aes(diff)) +
  geom_histogram(bins = 100) +
  stat_interval()
  
  
```

We can also take a look at the interaction. Here, we look at the effect of the label for each level of complexity. For simplicity, we only look at the effect on the log odds ratio scale (i.e., not the probability scale).

```{r}
emmeans(mfull, "label", by = "complexity") %>% 
  pairs() %>% 
  gather_emmeans_draws() %>% 
  mean_qi(.value, .width = c(0.5, 0.8, 0.95))
  
  
```

```{r}
emmeans(mri, "label", by = "complexity") %>% 
  pairs() %>% 
  gather_emmeans_draws() %>% 
  mean_qi(.value, .width = c(0.5, 0.8, 0.95))
```

These results also do not show a reliable effect of warning label on the 95% scale.

### Main Effects Only

Following the preregistration, we also run a model without the interaction of the fixed effects (i.e., main effects only). We again begin with the maximal random-effects structure justified by the design.

```{r, include=FALSE, echo = TRUE}
mme_full <- stanova_brm(nsucc | trials(nt) ~ label + complexity + (complexity|newid),
                     data = dla, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mme_full)
```
We again see no effect of the warning label (i.e., 95% CI for `label` includes 0).

We can also look at the results for the model without the random slope which shows the same results:

```{r, include=FALSE, echo = TRUE}
mme_ri <- stanova_brm(nsucc | trials(nt) ~ label + complexity + (1|newid),
                     data = dla, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mme_ri)
```


### Single Fixed-Effect Only


As a final test of, we also run an analysis on a model that only included a single fixed-effect.

We also need to aggregate the data to sample efficiently.

```{r}
dla2 <- dl %>% 
  group_by(label, newid) %>% 
  summarise(acc = mean(response), 
            nsucc = sum(response == 1),
            nt = n()) %>% 
  ungroup
```

We begin with a model that only includes fixed-effects for label and by-participant random intercepts.

```{r, include=FALSE, echo = TRUE}
mfe <- stanova_brm(nsucc | trials(nt) ~ label + (1|newid),
                     data = dla2, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mfe)
```

This model converged successfully, but showed no effect of label.



## Compare Predicted and Observed

For generalized linear mixed models the predicted marginal means do not necessarily have to correspond to the observed marginal means, especially for lower-order terms. Consequently, it makes sense to compare both observed and predicted means to see whether both agree qualitatively and quantitatively. If there are large disagreements, results should be interpreted carefully.


### Label

First we check the agreement for the effect of label. We compare the observed mean proportions against the predictions of three models. The maximal model with interaction, the minimal model with interaction, and the main-effect only model (i.e., only fixed-effect is label).

```{r, message=FALSE}
dl %>% 
  group_by(label) %>% 
  summarise(prop = mean(response)) %>% 
  mutate(
    full = get_est(emmeans(mfull, "label", type = "response")), 
    minimal = get_est(emmeans(mri, "label", type = "response")),
    me_only = get_est(emmeans(mfe, "label", type = "response")), 
  )
```

For the effect of label, the predicted response proportions are consistently smaller than the observed response proportions. In addition, there are rather small differences between the different models. This suggests that the main difference between model and data is due to the random-effects. Nevertheless, observed and predicted response proportions agree qualitatively. When the warning label is present, the proportion of betting seems to be slightly larger (note that this difference is NOT significant). 


## Model Evaluation

```{r, include = FALSE}
library("afex")
```


All models show at least qualitative agreement between observed and predicted response proportions, so we would be willing to interpret the results. 

In terms of effects tests, the different models agree as well. There is no evidence for an effect of label. Furthermore, if anything, there is a backfire effect that the warning label increases gambling.

Given the very strong agreement in, the choice of which model is the "best" seems not particularly consequential. Here we use the maximal model.

## Figure

The figure of the results is based on the best (i.e., minimal) model that includes the interaction.

```{r, fig.width=3.5, fig.height=3.5}
afex_plot(mfull, "complexity", "label", dodge = 0.3,
          data_alpha = 0.2, mapping = c("linetype", "fill", "color", "shape"),
          data_arg = list(
            position = 
              ggplot2::position_jitterdodge(
                jitter.width = 0.2, 
                jitter.height = 0.05, 
                dodge.width = 0.3  ## needs to be same as dodge
                )), dv = "acc", data = dla, id = "newid") +
  ylab("Probability to gamble")

```

We also create a figure for the paper.

```{r, fig.width=3.5, fig.height=3.5}
theme_set(theme_bw(base_size = 16) + 
            theme(legend.position="bottom"))

afex_plot(mfull, "label", 
          mapping = c(""),
          data_geom = geom_count, 
          data_arg = list(color = "darkgrey"),
          point_arg = list(size = 3.5), 
          error_arg = list(size = 2, width = 0), 
          factor_levels = list(label = c("Warning", "Control")),
          dv = "response", data = dl, id = "newid") +
  ylab("Probability to gamble") + xlab("Label") +
  guides(shape = FALSE) + 
  scale_size_area() +
  geom_line(aes(group = 1), size = 2)
 ggsave("plot1.png", device = "png", 
       width = 9, height = 9, units = "cm", 
       dpi = 600)

```


## Effect Size

The effect size for binomial data is odds ratio (OR). 

```{r}
emmeans(mfull, c("label"), type = "response") %>% 
  pairs %>% 
  update(by = NULL) %>% 
  summary(adjust = "holm", infer = TRUE)
```

For reference, again the predicted marginal means of the model.

```{r}
emmeans(mfull, c("label"), type = "response") 
```


# Exploratory Analysis

Following our preregistration, we also inspect whether the additional covariates affect the probability to gamble.

```{r}
dfull <- left_join(dla, add_vars, by = "newid")
## remove participant where gender is na
dfull2 <- dfull %>% 
  filter(!is.na(gender)) %>% 
  droplevels
covariates <- c("gender", "age_z", "freq_z", "psg_z")

```

## Gender

```{r, include=FALSE}
mgender_main <- stanova_brm(nsucc | trials(nt) ~ label*complexity + gender +
                           (complexity|newid),
                     data = dfull2, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mgender_main)
```


```{r, include=FALSE}
mgender_inter <- stanova_brm(nsucc | trials(nt) ~ label*complexity * gender +
                           (complexity|newid),
                     data = dfull2, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mgender_inter)
```

For gender, neither model shows an effect of `label`. However, in the model with interaction, the control condition for female participants is below the intercept. Does this mean that we see a differential label effect for gender?

```{r}
emmeans(mgender_inter, "label", by = "gender", type = "response") %>% 
  gather_emmeans_draws() %>% 
  mutate(prob = plogis(.value)) %>% 
  mutate(lab_gend = label:gender) %>% 
  ungroup %>% 
  compare_levels(prob, by = lab_gend) %>% 
  median_qi() %>% 
  slice(c(2,5))
```
As this table shows, the difference between the two labels includes 0 for either gender. Hence, there is no evidence for a differential effect of label across genders.

## Age

```{r, include=FALSE}
mage_main <- stanova_brm(nsucc | trials(nt) ~ label*complexity + age_z +
                           (complexity|newid),
                     data = dfull2, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mage_main)
```


```{r, include=FALSE}
mage_inter <- stanova_brm(nsucc | trials(nt) ~ label*complexity * age_z +
                           (complexity|newid),
                     data = dfull2, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mage_inter)
```

For age we also find that the CIs for the main effect of `label` still includes 0 in all cases. 

## Gambling Frequency

```{r, include=FALSE}
mfreq_main <- stanova_brm(nsucc | trials(nt) ~ label*complexity + freq_z +
                           (complexity|newid),
                     data = dfull2, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mfreq_main)
```


```{r, include=FALSE}
mfreq_inter <- stanova_brm(nsucc | trials(nt) ~ label*complexity * freq_z +
                           (complexity|newid),
                     data = dfull2, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mfreq_inter)
```

For gambling frequency we also find that the CIs for the main effect of `label` still includes 0 in all cases. 

## PSG

```{r, include=FALSE}
mpsg_main <- stanova_brm(nsucc | trials(nt) ~ label*complexity + psg_z +
                           (complexity|newid),
                     data = dfull2, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mpsg_main)
```


```{r, include=FALSE}
mpsg_inter <- stanova_brm(nsucc | trials(nt) ~ label*complexity * psg_z +
                           (complexity|newid),
                     data = dfull2, family = binomial,
                     iter = 6000, warmup = 1000, chains = 4)
```

```{r}
summary(mpsg_inter)
```

For PSG we also find that the CIs for the main effect of `label` still includes 0 in all cases. 
