---
title: "Analysis Football Gambling Study"
author: "Henrik"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
library("checkpoint")
create_checkpoint("2021-02-18", project_dir=".")
use_checkpoint("2021-02-18")
```

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(dpi=200, out.width="70%", fig.asp = 0.618,
                      fig.width=4, fig.align = "center")
options(width = 110)
options("dplyr.summarise.inform" = FALSE)
options(pillar.sigfig = 3)
options(mc.cores = parallel::detectCores()) # fitting uses multicore by default
```


# Preparation

```{r, message=FALSE, warning=FALSE, results='hide'}
library("tidyverse")
#library("tidylog")
theme_set(theme_bw() + 
            theme(panel.grid.major.x = element_blank(), 
                  panel.grid.minor.x = element_blank()))
library("brms")
library("tidybayes")
library("BayesFactor")
library("binom")
par_labels <- c("Gamble at all?", 
                "Gamble everything?", 
               "Proportion bet?")
cond_labels <- c("None", "Yellow")
ylabel <- "Gambling message"

## ids_exclude <- c("F.0460", "F.0539", "F.0282", "F.0026", "F.0447")  
## exclusion based on email from Leo, should result in 1003 participants
## is now checked algorithmically below
```

## Load & Prepare Data

We first load in the data from all participants and transform variables into correct type. We also perform some checks on the data to confirm that it matches our expectations (i.e., in size and structure).

```{r, message=FALSE, warning=FALSE}
captchas_all <- read_csv("data/captchas_data.csv")

## ids that should redirect from captchas to main task
ids_redirect <- captchas_all %>% 
   mutate(
    pptid = factor(pptid)
   ) %>% 
  filter(progress == "redirect") %>% 
  select(pptid)

covariates <- read_csv("data/questionnaire_data.csv") %>% 
  mutate(across(starts_with("ENH"), ~case_when(
    . == "Almost never/never" ~ 0,
    . == "Sometimes" ~ 1,
    . == "Often" ~ 2, 
    . == "Almost always" ~ 3, 
    TRUE ~ NA_real_))) %>% 
  mutate(across(starts_with("PGSI"), ~case_when(
    . == "Never" ~ 0,
    . == "Sometimes" ~ 1,
    . == "Most of the time" ~ 2, 
    . == "Almost always" ~ 3, 
    TRUE ~ NA_real_))) %>% 
  mutate(pptid = factor(pptid))
# map(covariates[,-(1:8)], ~sort(unique(.)))
## PGSI
# 0 = never
# 1 = sometimes
# 2 = most often / often
# 3 = always


## we only retain bets from participants that were both redirected and
## for which we have covariates
ids_covariates <- covariates %>% 
  select(pptid) 

ids_use <- inner_join(ids_covariates, ids_redirect)

bets <- read_csv("data/bets_data.csv") %>% 
  mutate(
    pptid = factor(pptid),
    Condition = factor(Condition, levels = 
                         c("Control", "Treatment"), 
                       labels = cond_labels)
  ) %>% 
  filter(pptid %in% ids_use$pptid) %>% 
  droplevels()
colnames(bets) <- tolower(colnames(bets))

stopifnot(length(levels(bets$pptid)) == 1003)  ## this number is hand checked

## make sure spent and unspent money for each participant is 3
bets %>% 
  group_by(pptid) %>% 
  summarise(all = sum(stake)) %>% 
  {all(.$all == 3)} %>% 
  stopifnot()

bets <- bets %>% 
  #filter(bet.description != "Unspent") %>% 
  mutate(
    decimal_odds = potential.payout/stake,
    fractional_odds = (potential.payout - stake) /stake
  )

only_bets <-  bets %>% 
  filter(bet.description != "Unspent")

stopifnot(all.equal(min(only_bets$decimal_odds, na.rm = TRUE), 1.4)) ## hand checked
stopifnot(all.equal(max(only_bets$decimal_odds), 126)) ## hand checked

used <- bets %>% 
  filter(bet.description != "Unspent") %>% 
  group_by(pptid, .drop = FALSE) %>% 
  summarise(bet = sum(stake))

used <- left_join(used, unique(select(bets, pptid, condition)))

riskiness <- bets %>% 
  filter(bet.description != "Unspent") %>% 
  group_by(pptid, .drop = FALSE) %>% 
  summarise(decimal_odds = mean(decimal_odds)) %>% 
  mutate(scaled_risk = (decimal_odds - 1.4) / (126 - 1.4))
riskiness <- left_join(riskiness, unique(select(bets, pptid, condition)))

#table(used$bet)
stopifnot(!any(is.na(used$bet)))

```

Then we create the our DV, proportion bet, as follows (note that the initial endowment was £3):
$$\texttt{prop_bet} = \frac{\texttt{amount bet}}{3}$$

```{r, message=FALSE, warning=FALSE, include=FALSE}
part2 <- used %>% 
  mutate(new_prop = bet / 3) 
```

```{r, include=FALSE}

pgsi <- covariates %>% 
  #select(-starts_with("Motives")) %>% 
  pivot_longer(starts_with("PGSI")) %>% 
  group_by(pptid) %>% 
  summarise(pgsi = sum(value))

motives <- covariates %>% 
  #select(-starts_with("Motives")) %>% 
  pivot_longer(starts_with("ENH")) %>% 
  group_by(pptid) %>% 
  summarise(motives = sum(value))

part2 <- left_join(part2, pgsi) %>% 
  left_join(motives) %>% 
  mutate(pgsi_c = pgsi - mean(pgsi),
         motives_c = motives - mean(motives))
```


The analysis is based on the following number of participants 

```{r}
nrow(part2) ## number of participants
part2 %>% 
  group_by(condition) %>% 
  tally()
```


# Distribution of DV

Our DV clearly does not look normally distributed and shows some clear bump at certain prominent numbers.

```{r}
part2 %>% 
  ggplot(aes(new_prop)) +
  geom_histogram(binwidth = 0.025)
```


Binomial confidence or credibility intervals for the probability to gamble at all:

```{r}
binom.confint(nrow(part2) - sum(part2$new_prop == 0), nrow(part2))
```



# Zero-One Inflated Beta Regression

We use a custom parameterization of a zero-one-inflated beta-regression model (see also [here](https://vuorre.netlify.com/post/2019/02/18/analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/)). The likelihood of the model is given by:

$$\begin{align}
f(y) &= (1 - g) & & \text{if } y = 0 \\
f(y) &= g \times e & & \text{if } y = 1 \\
f(y) &= g \times (1 - e) \times \text{Beta}(a,b) & & \text{if } y \notin \{0, 1\} \\
a &= \mu \times \phi \\
b &= (1-\mu) \times \phi
\end{align}$$

Where $g$ is the zero inflation probability (`zipp`) and reflects the probability to gamble, $e$ is the conditional one-inflation probability (`coi`) or conditional probability to gamble everything (i.e., conditional probability to have a value of one, if one gambles), $\mu$ is the mean of the beta distribution (`Intercept`), and $\phi$ is the precision of the beta distribution (`phi`). As we use `Stan` for modelling, we need to model on the real line and need appropriate link functions. For `\phi` the link is log (inverse is `exp()`), for all other parameters it is logit (inverse is `plogis()`).

We fit this model and add experimental condition as a factor to the three main model parameters (i.e., only the precision parameter is fixed across conditions). The following table provides the overview of the model and all model parameters and show good convergence.

```{r, eval=TRUE, include=FALSE}
zoib2 <- custom_family(
  "zoib2", dpars = c("mu", "phi", "zipp", "coi"),
  links = c("logit", "log", "logit", "logit"), lb = c(NA, 0, NA, NA),
  type = "real"
)

stan_funs <- "
/* zero-one-inflated beta log-PDF of a single response 
   * Args: 
   *   y: response value 
   *   mu: mean parameter of the beta part
   *   phi: precision parameter of the beta part
   *   zipp: zero-inflation probability parameter
   *   coi: conditional one-inflation probability
   * Returns:  
   *   a scalar to be added to the log posterior 
   */ 
   real zoib2_lpdf(real y, real mu, real phi,
                                    real zipp, real coi) {
     row_vector[2] shape = [mu * phi, (1 - mu) * phi]; 
     if (y == 0) { 
       return bernoulli_lpmf(0 | zipp); 
     } else if (y == 1) {
       return bernoulli_lpmf(1 | zipp) + bernoulli_lpmf(1 | coi);
     } else { 
       return bernoulli_lpmf(1 | zipp) + bernoulli_lpmf(0 | coi) + beta_lpdf(y | shape[1], shape[2]);
     } 
   }
"
stanvars <- stanvar(scode = stan_funs, block = "functions")


zoib_model <- bf(
  new_prop ~ condition,
  phi ~ 1,
  zipp ~ condition,
  coi ~ condition, 
  family = zoib2
)

np <- prior_string("target += logistic_lpdf(Intercept_zipp | 0, 1);", check = FALSE)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib <- brm(formula = zoib_model, data = part2, 
               stanvars = stanvars, prior = np, 
               iter = 26000, warmup = 1000, chains = 4) ## 100,000 post-warmup
  save(mzoib, file = tmp_model_filename, compress = "xz")
}
```





```{r}
#load("fits/model_zoib.rda")
summary(mzoib)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib, pars = "conditionYellow")
```


```{r, include=FALSE}
get_variables(mzoib)
```


The model does not have any obvious problems, even without priors for the condition specific effects.

## Posterior Predictive Checks

As expected the synthetic data generated from the model is able to adequately predict the two peaks at the boundary, but does not fully capture the peaks in between those. However, the mass of the distribution between the peaks seems to be at a similar location in both the observed and the synthetic data.

```{r}
## we need to create a custom RNG function for this case
posterior_predict_zoib2 <- function(i, prep, ...) {
  zi <- brms:::get_dpar(prep, "zipp", i)
  coi <- brms:::get_dpar(prep, "coi", i)
  mu <- brms:::get_dpar(prep, "mu", i = i)
  phi <- brms:::get_dpar(prep, "phi", i = i)
  hu <- runif(prep$nsamples, 0, 1)
  hu2 <- runif(prep$nsamples, 0, 1)
  #one_or_zero <- runif(prep$nsamples, 0, 1)
  ifelse(hu > zi, 0, 
    ifelse(hu2 < coi, 1, 
           rbeta(prep$nsamples, shape1 = mu * phi, shape2 = (1 - mu) * phi)
  ))
}

```

```{r, fig.width=6, out.width="100%"}
options(mc.cores = 1)
pp1 <- pp_check(mzoib, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 460)) +
  theme(legend.position = "none")
pp1
ggsave(plot = pp1, filename = "figures/ppp.png", width = 8, height = 6)
options(mc.cores = parallel::detectCores())
```

## Model Estimates

We first give the table showing the posterior means and 95% CIs.

```{r, warning=FALSE}

lpars <- mzoib %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(.variable != "b_phi_Intercept") %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "conditionYellow") ~ "effect",
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(None = Intercept, 
         Yellow = Intercept + effect) %>% 
  select(-Intercept, -effect) %>% 
  pivot_longer(cols = c(None, Yellow), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

condpars %>% 
  group_by(parameter, condition) %>% 
  mean_qi()

```

For the zero-one inflated components, we can compare the model estimates with the data. Not unsurprisingly, they match quite well. 

```{r}
part2 %>% 
  group_by(condition) %>% 
  summarise(gamble_at_all = 1 - mean(new_prop  == 0), 
            gamble_everything = mean(new_prop[new_prop != 0] == 1))
```

The following is the main results figure on the level of the message conditions.


```{r, out.width="100%", fig.width = 9.5, fig.asp=0.5}
## plots in which CIs sizes are relative to each other.
tmp <- condpars %>% 
  group_by(parameter, condition) %>% 
  mean_qi()
tmp <- tmp %>% 
  mutate(width = .upper - .lower) %>% 
  summarise(mwidth = mean(width))
pr1 <- condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") + ylab(ylabel) +
  scale_x_continuous(labels = scales::percent_format(1))
tmp2 <- pr1$data %>% 
  group_by(parameter) %>% 
  summarise(min = min(estimate), 
            max = max(estimate)) %>% 
  mutate(fwidth = max - min) %>% 
  mutate(newmin = min, 
         newmax = max, 
         mid = min + fwidth * 0.5)
tmp2$fac <- tmp$mwidth/tmp2$fwidth
tmp2$ciwdith <- tmp$mwidth
tmp2 <- tmp2 %>% 
  mutate(newwidth = ciwdith * 1/min(fac)) %>% 
  mutate(newmin = mid - newwidth/2,
         newmax = mid + newwidth/2)
tmpl <- tmp2 %>% 
  select(parameter, newmin, newmax) %>% 
  pivot_longer(cols = c(newmin, newmax), 
               names_to = "bounds", values_to = "estimate") %>% 
  mutate(condition = NA)
pr1 <- pr1 +
  geom_blank(data = tmpl)

pr1 + theme_bw(base_size = 17)
ggsave(pr1  + theme_bw(base_size = 17), filename = "figures/res_e1a.png", 
       width = 9.5, height = 4.5)
ggsave(pr1  + theme_bw(base_size = 17) + theme(panel.grid.minor.x = element_blank()), 
       filename = "figures/res_e1b.png", 
       width = 9.5, height = 4.5)
ggsave(pr1  + theme_bw(base_size = 17) + theme(
  panel.grid.minor.x = element_blank(), 
  panel.grid.major.x = element_blank()), 
       filename = "figures/res_e1c.png", 
       width = 9.5, height = 4.5)
pr1use <- pr1  + theme_bw(base_size = 17) + theme(
  panel.grid.minor.x = element_blank(), 
  panel.grid.major.x = element_blank())
```


```{r, out.width="100%", fig.width = 9.5, fig.asp=0.5, eval=FALSE}
## not used at the moment because of preceding chunk 
pr1 <- condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  geom_halfeyeh() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") + ylab(ylabel) +
  scale_x_continuous(labels = scales::percent_format(1))
pr1 + theme_bw(base_size = 17)
ggsave(pr1  + theme_bw(base_size = 17), filename = "figures/res_e1.png", 
       width = 9.5, height = 4.5)
```

## Difference distribution versus no message condition

We can also focus and look at the difference distributions from the no message condition.

```{r}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, labels = "          "
  ))
comppars %>% 
  group_by(parameter, condition) %>% 
  mean_qi(.width = c(0.8, 0.95))
```

Same as a figure.


```{r, out.width="100%", fig.width = 9.5, fig.asp=0.4}

pr2 <- comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey", size = 0.6) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Difference from no message condition (on probability/proportion scale)") + 
  ylab("   ") +
  scale_x_continuous(labels = scales::percent_format(1)) 

#pr2 + theme(axis.ticks.y = element_blank())

ciwidths <- comppars %>% 
  group_by(parameter, condition) %>% 
  mean_qi() %>% 
  mutate(width = .upper - .lower) %>% 
  summarise(mwdith = mean(width))

tmp <- pr2$data %>% 
  group_by(parameter) %>% 
  summarise(min = min(estimate), 
            max = max(estimate)) %>% 
  mutate(pwidth = max-min) %>% 
  mutate(mid = min + (max-min)/2) %>% 
  mutate(ciwdith = ciwidths$mwdith) %>% 
  mutate(newwidth = ciwdith * max(pwidth/ciwdith)) %>% 
  mutate(newmin = mid - newwidth/2,
         newmax = mid + newwidth/2)
tmpl <- tmp %>% 
  select(parameter, newmin, newmax) %>% 
  pivot_longer(cols = c(newmin, newmax), 
               names_to = "bounds", values_to = "estimate") %>% 
  mutate(condition = NA)
pr2 <- pr2 +
  geom_blank(data = tmpl)

pr2 + theme_bw(base_size = 17) + 
  theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank()
  )

ggsave(pr2  + theme_bw(base_size = 17) + theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank()
  ), filename = "res_e2.png", 
       width = 9.5, height = 4)
pr2use <- pr2  + theme_bw(base_size = 17) + theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank(),
    axis.ticks.y = element_blank()
  )
```

```{r}
ggsave(plot = cowplot::plot_grid(pr1use, pr2use, ncol = 1, 
                                 rel_heights = c(4.5, 4)), 
       filename = "figures/res_both.png", 
       width = 9.5, height = 8.5)

```

## All Difference Distributions with Possible Priors

The following plot shows the estimated differences of the message condition from the no message control condition with overlaid density estimate (in black) and some possible prior distributions in colour (note again that the model did not actually include any priors). These differences are shown on the linear scale before applying the logistic link function. These priors are normal priors (who have a higher peak at 0 compared to Cauchy and t) with different SDs.

```{r}
prior_pars <- lpars %>% 
  filter(type != "Intercept") %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels)) 
# prior_pars %>% 
#   unique(.$.variable)
```

```{r, out.width="100%", fig.width=4, warning=FALSE}
prior_plot <- prior_pars %>% 
  ggplot() +
  geom_histogram(aes(.value, after_stat(density)), binwidth = 0.001) +
  geom_density(aes(.value)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = c(0.25)), 
                mapping =  aes(color = "SD = 0.25")) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = c(0.5)), 
                mapping =  aes(color = "SD = 0.5")) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = c(1)), 
                mapping =  aes(color = "SD = 1.00")) +
  geom_vline(xintercept = 0, color = "grey") +
  facet_grid(cols = vars(parameter), rows = vars("No message vs. yellow"),scales = "free_x") + 
  guides(colour = guide_legend("prior width")) +
  labs(x = "estimate on linear scale") +
  ggsci::scale_color_lancet()
prior_plot
```

```{r, eval=FALSE}
if (dir.exists("../figures/")) {
  ggsave("../figures/e3_prior_plot.png", device = "png", 
         width = 19, height = 5, units = "cm", 
         dpi = 600)
  ggsave("../figures/e3_prior_plot.pdf", device = "pdf", 
         width = 19, height = 5, units = "cm", 
         dpi = 600)
}
```


```{r, eval=FALSE}

plogis(qnorm(0.975) * 1) - 0.5

```


In this figure we considered three prior width. For a prior width of SD = 0.25 we expect with 95% that the largest possible effect we observe is `r scales::percent(plogis(qnorm(0.975) * 0.25) - 0.5, accuracy = 0.01)` on the response scale. For a prior width of SD = 0.5 we expect with 95% that the largest possible effect we observe is `r scales::percent(plogis(qnorm(0.975) * 0.5) - 0.5, accuracy = 0.01)` on the response scale. For a prior width of SD = 0.5 we expect with 95% that the largest possible effect we observe is `r scales::percent(plogis(qnorm(0.975) * 1) - 0.5, accuracy = 0.01)` on the response scale.

What the image shows is that for "gamble at all" and "proportion bet" there appears to be evidence for the null. We see that for all priors the posterior density at 0 (i.e., y-axis position at which the black line crosses the 0 line) is larger then the prior density at 0 (i.e., the density of the prior curve at 0). However, for the narrow prior the evidence appears to be only anecdotal (i.e., ratio of posterior density to prior density at 0 is smaller than 3). 

For gamble everything, we only see anecdotal evidence. The narrow prior provides anecdotal evidence for a backfire effect. The other two priors appear to provide anecdotal evidence for the null.  


# Model With Covariates

## Plot of Relationships and BANOVA

The covariates do not differ between conditions (BF provide evidence for the null).

```{r, warning=FALSE}
1/anovaBF(pgsi ~ condition, part2, progress = FALSE)
1/anovaBF(motives ~ condition, part2, progress = FALSE)
```

The following table shows descriptives for the covariates:

```{r}
part2 %>% 
  group_by(condition) %>% 
  summarise(across(c(pgsi, motives), c(mean = mean, sd = sd)))
```

The following plot shows the relationships of the covariates among each other and with proportion bet.

```{r, message=FALSE, out.width="100%", fig.width=12, fig.height=4, fig.asp=0.4}
tmpp1 <- part2 %>% 
  #filter(!(new_prop %in% c(1))) %>% 
  ggplot(aes(x = pgsi, y = motives)) +
  geom_jitter(alpha = 0.2, width = 0.01, height = 0.2) +
  geom_smooth() +
  geom_smooth(method = "lm", color = "red")
tmpp2 <- part2 %>% 
  #filter(!(new_prop %in% c(1))) %>% 
  ggplot(aes(x = new_prop, y = motives)) +
  geom_jitter(alpha = 0.2, width = 0.01, height = 0.2) +
  geom_smooth() +
  geom_smooth(method = "lm", color = "red")
tmpp3 <- part2 %>% 
  #filter(!(new_prop %in% c(1))) %>% 
  ggplot(aes(x = new_prop, y = pgsi)) +
  geom_jitter(alpha = 0.2, width = 0.01, height = 0.2) +
  geom_smooth() +
  geom_smooth(method = "lm", color = "red")
cowplot::plot_grid(tmpp1, tmpp2, tmpp3, nrow = 1)
```

The figures show some relationships which can also be seen when just looking at the correlation.

```{r}
cor.test(part2$pgsi, part2$motives)
cor.test(part2$pgsi, part2$new_prop)
cor.test(part2$motives, part2$new_prop)
```

The figure below provides an alternative visualisation of the relationships between covariates and betting behaviour. In particular, participants were categorized into one of three experimental betting behavior groups: participants who did not bet at all (“none”, 39% of participants), participants who bet some of their money (19% of participants), and participants who bet “all” of their money (42%). For both gambling scales we see a positive relationship between the betting behavior group and the gambling score. Participants who bet more have on average higher scores on the two gambling scales. 


```{r, eval=FALSE}
part2 %>% 
  summarise(gamble_at_all = 1 - mean(new_prop  == 0), 
            gamble_everything = mean(new_prop[new_prop != 0] == 1), 
            proportion_bet_rest = mean(new_prop[!(new_prop %in% c(0, 1))]))

part2 %>% 
  filter(!(new_prop %in% c(0, 1))) %>% 
  with(cor.test(new_prop, motives))

part2 %>% 
  filter(!(new_prop %in% c(1))) %>% 
  with(cor.test(new_prop, motives))


part2 %>% 
  filter(!(new_prop %in% c(0, 1))) %>% 
  ggplot(aes(x = new_prop, y = motives)) +
  geom_point(alpha = 0.2)

part2 %>% 
  #filter(!(new_prop %in% c(1))) %>% 
  ggplot(aes(x = new_prop, y = motives)) +
  geom_jitter(alpha = 0.2, width = 0.01, height = 0.2) +
  geom_smooth()

part2 %>% 
  #filter(!(new_prop %in% c(1))) %>% 
  ggplot(aes(x = new_prop, y = pgsi)) +
  geom_jitter(alpha = 0.2, width = 0.01, height = 0.2) +
  geom_smooth()
```


```{r}

part2 <- part2 %>% 
  mutate(gamble_cat = if_else(new_prop == 1, "all", if_else(new_prop == 0, "none", "some"))) %>% 
  mutate(gamble_cat = factor(gamble_cat, levels = c("none", "some", "all")))
#library("ggbeeswarm")

prop.table(table(part2$gamble_cat))

cvp1 <- part2 %>% 
  #filter(!(new_prop %in% c(0))) %>% 
  #ggplot(aes(x = interaction(exp_cond, gamble_cat), y = pgsi)) +
  ggplot(aes(x = gamble_cat, y = pgsi)) +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
  #geom_quasirandom(alpha = 0.2) +
  stat_summary(fun.data = ~mean_se(., mult = 1.96)) +
  xlab("Proportion bet") + ylab("Enhancement Motives") +
  theme_bw(base_size = 15) + theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank()
  )

cvp2 <- part2 %>% 
  #filter(!(new_prop %in% c(0))) %>% 
  #ggplot(aes(x = interaction(exp_cond, gamble_cat), y = pgsi)) +
  ggplot(aes(x = gamble_cat, y = motives)) +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
  #geom_quasirandom(alpha = 0.2) +
  stat_summary(fun.data = ~mean_se(., mult = 1.96)) +
  xlab("Proportion bet") + ylab("Problem Gambling Severity Index") + 
  theme_bw(base_size = 15) + theme(
    panel.grid.minor.x = element_blank(), 
    panel.grid.major.x = element_blank()
  )
cvp <- cowplot::plot_grid(cvp2, cvp1)
ggsave(filename = "figures/cov_plot.png", plot = cvp, width = 6.5, height = 4)

cvp

```

This is supported by Bayesian ANOVAs for the enhancement motives scale, with a Bayes factor of over 700,000 for the effect of betting behavior group on motives score. However, there was evidence for a null effect (BF around 50 for the null) for the PGSI effect even though it showed descriptively the same pattern. 

Furthermore, the effect on the motive score was not moderated by gambling message condition. The evidence for the absence of a main effect of condition was ambigous (around 1), but there was substantial evidence for the absence of the interaction (BF > 30).

```{r, eval=FALSE}
anovaBF(pgsi ~ gamble_cat, as.data.frame(part2), progress = FALSE)
anovaBF(motives ~ gamble_cat, as.data.frame(part2), progress = FALSE)
```

```{r, warning=FALSE}
bfa1 <- anovaBF(pgsi ~ gamble_cat*condition, as.data.frame(part2), progress = FALSE)
bfa1
bfa1[2]/bfa1

bfa2 <- anovaBF(motives ~ gamble_cat*condition, as.data.frame(part2), progress = FALSE)
bfa2
bfa2[2]/bfa2
```



## Model with Main Effects

```{r, eval=TRUE, include=FALSE}
zoib_model2 <- bf(
  new_prop ~ condition + pgsi_c + motives_c,
  phi ~ 1,
  zipp ~ condition + pgsi_c + motives_c,
  coi ~ condition + pgsi_c + motives_c, 
  family = zoib2
)

tmp_model_filename <- "model_fits/model_zoib2.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib2 <- brm(formula = zoib_model2, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib2, file = tmp_model_filename, compress = "xz")
}
```

```{r}
summary(mzoib2)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib2, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib2, pars = "conditionYellow")
```
We also check the chains for the PGSI and motives scales.
```{r, fig.asp=1.0}
plot(mzoib2, pars = "pgsi")
plot(mzoib2, pars = "motives")
```


```{r, include=FALSE}
get_variables(mzoib2)
```

```{r, fig.width=6, out.width="100%"}
options(mc.cores = 1)
pp_check(mzoib2, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350))
options(mc.cores = parallel::detectCores())
```



```{r}

lpars <- mzoib2 %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(!(.variable %in% c("b_phi_Intercept"))) %>%
  filter(!str_detect(.variable, "pgsi|motives")) %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "conditionYellow") ~ "effect"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))
#unique(lpars$.variable)

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         treatment = Intercept + effect) %>% 
  select(-Intercept, -effect) %>% 
  pivot_longer(cols = c(control, treatment), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

```

```{r, out.width="100%", fig.width=6, fig.asp=0.55}
condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(1))
```


```{r, out.width="100%", fig.width=6, fig.asp=0.55}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    labels = c("difference")))
comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
    xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("") +
  scale_x_continuous(labels = scales::percent_format(1))
```

## Model with Main Effects (only PGSI)

```{r, eval=TRUE, include=FALSE}
zoib_model2p <- bf(
  new_prop ~ condition + pgsi_c ,
  phi ~ 1,
  zipp ~ condition + pgsi_c,
  coi ~ condition + pgsi_c, 
  family = zoib2
)

tmp_model_filename <- "model_fits/model_zoib2p.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib2p <- brm(formula = zoib_model2p, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib2p, file = tmp_model_filename, compress = "xz")
}
```

```{r}
summary(mzoib2p)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib2p, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib2p, pars = "conditionYellow")
```
We also check the chains for the PGSI and motives scales.
```{r, fig.asp=1.0}
plot(mzoib2p, pars = "pgsi")
```

## Model with Main Effects (only Motives)


```{r, eval=TRUE, include=FALSE}
zoib_model2m <- bf(
  new_prop ~ condition + motives_c,
  phi ~ 1,
  zipp ~ condition + motives_c,
  coi ~ condition + motives_c, 
  family = zoib2
)

tmp_model_filename <- "model_fits/model_zoib2m.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib2m <- brm(formula = zoib_model2m, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib2m, file = tmp_model_filename, compress = "xz")
}
```

```{r}
summary(mzoib2m)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib2m, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib2m, pars = "conditionYellow")
```
We also check the chains for the PGSI and motives scales.
```{r, fig.asp=1.0}
plot(mzoib2m, pars = "motives")
```


```{r, include=FALSE}
get_variables(mzoib2)
```

```{r, fig.width=6, out.width="100%"}
options(mc.cores = 1)
pp_check(mzoib2m, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350))
options(mc.cores = parallel::detectCores())
```



```{r}

lpars <- mzoib2m %>% 
  gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(!(.variable %in% c("b_phi_Intercept"))) %>%
  filter(!str_detect(.variable, "pgsi|motives")) %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "conditionYellow") ~ "effect"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))
#unique(lpars$.variable)

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         treatment = Intercept + effect) %>% 
  select(-Intercept, -effect) %>% 
  pivot_longer(cols = c(control, treatment), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

```

```{r, out.width="100%", fig.width=6, fig.asp=0.55}
condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(1))
```


```{r, out.width="100%", fig.width=6, fig.asp=0.55}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    labels = c("difference")))
comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
    xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("") +
  scale_x_continuous(labels = scales::percent_format(1))
```



## Model With Interactions

```{r, eval=TRUE, include=FALSE}
zoib_model3 <- bf(
  new_prop ~ condition * (pgsi_c + motives_c),
  phi ~ 1,
  zipp ~ condition * (pgsi_c + motives_c),
  coi ~ condition * (pgsi_c + motives_c), 
  family = zoib2
)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib3.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib3 <- brm(formula = zoib_model3, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib3, file = tmp_model_filename, compress = "xz")
}
```



```{r}
summary(mzoib3)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib3, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no messafe condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib3, pars = "conditionYellow$")
```

```{r, include=FALSE}
get_variables(mzoib2)
```

```{r, fig.width=6, fig.height=6, out.width="100%"}
options(mc.cores = 1)
pp_check(mzoib3, type = "hist", binwidth = 0.025, nsamples = 11) +
  coord_cartesian(ylim = c(0, 350))
options(mc.cores = parallel::detectCores())
```



```{r}

lpars <- mzoib3 %>% 
gather_draws(`b_.*`, regex = TRUE) %>% 
  filter(!(.variable %in% c("b_phi_Intercept"))) %>%
  filter(!str_detect(.variable, "pgsi|motives")) %>% 
  mutate(type = case_when(
    str_detect(.variable, "Intercept") ~ "Intercept",
    str_detect(.variable, "conditionYellow") ~ "effect"
  )) %>%  
  mutate(parameter = case_when(
    str_detect(.variable, "zipp") ~ "g",
    str_detect(.variable, "coi") ~ "f",
    TRUE ~ "mu"
  ))
#unique(lpars$.variable)

condpars <- lpars %>% 
  pivot_wider(id_cols = c(.chain:.draw, parameter, parameter), 
              names_from = type, values_from = .value) %>% 
  mutate(control = Intercept, 
         treatment = Intercept + effect) %>% 
  select(-Intercept, -effect) %>% 
  pivot_longer(cols = c(control, treatment), 
               names_to = "condition", values_to = "estimate") %>% 
  mutate(estimate = plogis(estimate)) %>% 
  mutate(parameter = factor(
    x = parameter, 
    levels = c("g", "f", "mu"), 
    labels = par_labels))

```

```{r, out.width="100%", fig.width=6}
condpars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  #stat_histintervalh(breaks = 40) +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
  xlab("Probability/Proportion") +
  scale_x_continuous(labels = scales::percent_format(1))
```


```{r, out.width="100%", fig.width=6}
comppars <- condpars %>% 
  group_by(parameter) %>% 
  compare_levels(estimate, by = condition) %>% 
  mutate(condition = factor(
    x = condition, 
    labels = c("difference")))
comppars %>% 
  ggplot(aes(x = estimate, y = condition)) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye() +
  facet_wrap("parameter", scales = "free_x") +
    xlab("Difference from no message condition (on proportion/probability scale)") + 
  ylab("") +
  scale_x_continuous(labels = scales::percent_format(1))
```


## Model With Interactions (only PGSI)

```{r, eval=TRUE, include=FALSE}
zoib_model3p <- bf(
  new_prop ~ condition * (pgsi_c),
  phi ~ 1,
  zipp ~ condition * (pgsi_c),
  coi ~ condition * (pgsi_c), 
  family = zoib2
)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib3p.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib3p <- brm(formula = zoib_model3p, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib3p, file = tmp_model_filename, compress = "xz")
}
```



```{r}
summary(mzoib3p)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib3p, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib3p, pars = "conditionYellow$")
```

Is the overall effect of PGSI credibly negative?

```{r}
emmeans::emtrends(mzoib3p, "condition", "pgsi_c") %>% 
  gather_emmeans_draws() %>% 
  median_qi()

emmeans::emtrends(mzoib3p, "condition", "pgsi_c") %>% 
  gather_emmeans_draws() %>% 
  pivot_wider(id_cols = .draw, names_from = condition, 
              values_from = .value) %>% 
  mutate(Overall = (None + Yellow)/2) %>% 
  median_qi(Overall)

## same as:
# emmeans::emtrends(mzoib3p, "1", "pgsi_c") %>% 
#   gather_emmeans_draws() %>% 
#   median_qi()


```


## Model With Interactions (only Motives)

```{r, eval=TRUE, include=FALSE}
zoib_model3m <- bf(
  new_prop ~ condition * (motives_c),
  phi ~ 1,
  zipp ~ condition * (motives_c),
  coi ~ condition * (motives_c), 
  family = zoib2
)

# make_stancode(zoib_model, data = part2, stanvars = stanvars, prior = np)
# tmp <- make_standata(zoib_model, data = part2, stanvars = stanvars) 
# str(tmp)
# tmp$Y

tmp_model_filename <- "model_fits/model_zoib3m.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mzoib3m <- brm(formula = zoib_model3m, data = part2, 
                stanvars = stanvars, prior = np,
                iter = 26000, warmup = 1000, chains = 4)
  save(mzoib3m, file = tmp_model_filename, compress = "xz")
}
```



```{r}
summary(mzoib3m)
```

As a visual convergence check, we plot the density and trace plots for the four intercept parameters representing the no message condition or the overall mean (for `phi`).

```{r, fig.asp=1.2}
plot(mzoib3m, pars = "Intercept")
```

We can also plot the three parameters showing the difference distribution of the yellow message condition from the no message condition. These differences are given on the logit scale.

```{r, fig.asp=1.0}
plot(mzoib3m, pars = "conditionYellow$")
```

Is the overall effect of Motives credibly negative?

```{r}
emmeans::emtrends(mzoib3m, "condition", "motives_c") %>% 
  gather_emmeans_draws() %>% 
  median_qi()

emmeans::emtrends(mzoib3m, "condition", "motives_c") %>% 
  gather_emmeans_draws() %>% 
  pivot_wider(id_cols = .draw, names_from = condition, 
              values_from = .value) %>% 
  mutate(Overall = (None + Yellow)/2) %>% 
  median_qi(Overall)

## same as:
# emmeans::emtrends(mzoib3p, "1", "pgsi_c") %>% 
#   gather_emmeans_draws() %>% 
#   median_qi()


```

# Riskiness

For the analysis of riskiness, we had to exclude all participants that did not place a single bet. This led to the following N:

```{r}
risk2 <- riskiness %>% 
  filter(!is.na(decimal_odds))
risk2 %>% 
  group_by(condition) %>% 
  tally()
```

The distribution of riskiness is:

```{r}
risk2 %>% 
  ggplot(aes(scaled_risk)) +
  geom_histogram(binwidth = 0.01)
```

It turns out that there are two participants with a scaled riskiness of zero, both in the treatment condition. And no participants with a riskiness of 1.

```{r}
risk2 %>% 
  group_by(condition) %>% 
  summarise(n_zero = sum(scaled_risk == 0), 
            n_one = sum(scaled_risk == 1))
```

## Beta-Regression

We run the first analysis, using a beta-regression model, after excluding the two zeros.

```{r}
risk3 <- risk2 %>% 
  filter(scaled_risk != 0)
```

```{r, eval=TRUE, include=FALSE}
risk_frml2 <- bf(
  scaled_risk ~ condition,
  phi ~ 1
)

tmp_model_filename <- "model_fits/model_risk2.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mrisk2 <- brm(formula = risk_frml2, data = risk3, family = Beta())
  save(mrisk2, file = tmp_model_filename, compress = "xz")
}

```


The model does not show any obvious problems. In addition, we can see that the 95%-CI for the gambling message specific effect includes 0.

```{r}
summary(mrisk2)
```

```{r, fig.asp=1.0}
plot(mrisk2)
```

The data and the posterior predictive distribution look good.

```{r, fig.width=6, out.width="100%"}
pp_check(mrisk2, type = "hist", binwidth = 0.01, nsamples = 11)
```

## Zero-Inflated Beta-Regression

We re-run the analysis, using a zero-inflated beta-regression model.

```{r, eval=TRUE, include=FALSE}
risk_frml3 <- bf(
  scaled_risk ~ condition,
  zi ~ condition,
  phi ~ 1
)

tmp_model_filename <- "model_fits/model_risk3.rda"
if (file.exists(tmp_model_filename)) {
  load(tmp_model_filename)
} else {
  mrisk3 <- brm(formula = risk_frml3, data = risk2, family = zero_inflated_beta())
  save(mrisk3, file = tmp_model_filename, compress = "xz")
}

```


The model also does not show any obvious problems. As above, the 95% CIs of the condition effects contain 0 indicated no evidence that the warning label affects the riskiness of gambles.

```{r}
summary(mrisk3)
```

```{r, fig.asp=1.0}
plot(mrisk3)
```

As expected, the data and the posterior predictive distribution also look good.

```{r, fig.width=6, out.width="100%"}
pp_check(mrisk3, type = "hist", binwidth = 0.01, nsamples = 11)
```

